# Linux Pipes (|) — Many Real‑World Examples (Step‑by‑Step)

A **pipe** (`|`) sends the **output** of one command to the **input** of the next.

General pattern:
```bash
command1 | command2 | command3
```

> **Rule of thumb:** Each command does *one job*, and the pipe builds a workflow.

---

## 0) Setup a small “real” dataset (recommended)
Run these once to create sample files you can practice on:

```bash
mkdir -p pipe_lab
cd pipe_lab

# 1) Create a sample application log
cat > app.log << 'EOF'
2025-12-15 09:00:01 INFO  User login success user=rahul ip=10.0.0.11
2025-12-15 09:01:20 WARN  Slow query user=sonali ip=10.0.0.12 ms=2400
2025-12-15 09:02:10 ERROR DB connection failed user=rahul ip=10.0.0.11 code=DB100
2025-12-15 09:03:40 INFO  Order placed user=arjun ip=10.0.0.13 amount=499
2025-12-15 09:04:15 ERROR Payment failed user=sonali ip=10.0.0.12 code=PAY200
2025-12-15 09:05:05 INFO  User logout user=rahul ip=10.0.0.11
2025-12-15 09:06:30 WARN  API timeout user=arjun ip=10.0.0.13 ms=5200
2025-12-15 09:07:00 ERROR API returned 500 user=arjun ip=10.0.0.13 code=API500
EOF

# 2) Create a sample access log (space separated)
cat > access.log << 'EOF'
10.0.0.11 - - [15/Dec/2025:09:00:01 +0530] "GET /login HTTP/1.1" 200 123
10.0.0.12 - - [15/Dec/2025:09:01:20 +0530] "GET /products HTTP/1.1" 200 533
10.0.0.11 - - [15/Dec/2025:09:02:10 +0530] "POST /pay HTTP/1.1" 500 321
10.0.0.13 - - [15/Dec/2025:09:03:40 +0530] "GET /orders HTTP/1.1" 200 444
10.0.0.12 - - [15/Dec/2025:09:04:15 +0530] "POST /pay HTTP/1.1" 502 311
10.0.0.13 - - [15/Dec/2025:09:06:30 +0530] "GET /status HTTP/1.1" 200 88
10.0.0.13 - - [15/Dec/2025:09:07:00 +0530] "GET /status HTTP/1.1" 500 88
EOF

# 3) Create a sample CSV file
cat > sales.csv << 'EOF'
order_id,customer,city,amount,status
O1001,Rahul,Chennai,499,PAID
O1002,Sonali,Bengaluru,1200,FAILED
O1003,Arjun,Hyderabad,799,PAID
O1004,Rahul,Chennai,1500,PAID
O1005,Sonali,Bengaluru,300,FAILED
EOF
```

---

# 1) Example: Count how many ERROR lines are in a log
### Goal: “How many errors happened today?”

### Step 1 — View only error lines (filter)
```bash
grep "ERROR" app.log
```

### Step 2 — Count those lines
```bash
grep "ERROR" app.log | wc -l
```

✅ Output meaning: total number of ERROR events.

---

# 2) Example: Show last 2 ERRORs (recent errors only)
### Step 1 — Filter errors
```bash
grep "ERROR" app.log
```

### Step 2 — Get last 2 lines only
```bash
grep "ERROR" app.log | tail -n 2
```

---

# 3) Example: Find unique error codes from the log
### Goal: “Which error codes occurred?”

### Step 1 — Keep only ERROR lines
```bash
grep "ERROR" app.log
```

### Step 2 — Extract only `code=...`
```bash
grep "ERROR" app.log | grep -o "code=[A-Z0-9]*"
```

### Step 3 — Remove duplicates
```bash
grep "ERROR" app.log | grep -o "code=[A-Z0-9]*" | sort | uniq
```

---

# 4) Example: Top users who caused errors (frequency)
### Goal: “Which users are most associated with errors?”

### Step 1 — Filter error lines
```bash
grep "ERROR" app.log
```

### Step 2 — Extract `user=...`
```bash
grep "ERROR" app.log | grep -o "user=[a-z]*"
```

### Step 3 — Count and sort by highest
```bash
grep "ERROR" app.log | grep -o "user=[a-z]*" | sort | uniq -c | sort -nr
```

✅ `uniq -c` adds counts; `sort -nr` sorts by number descending.

---

# 5) Example: Top IPs from access logs (security / traffic)
### Goal: “Which IPs hit my site the most?”

### Step 1 — Extract the first column (IP)
```bash
cut -d' ' -f1 access.log
```

### Step 2 — Count repeated IPs
```bash
cut -d' ' -f1 access.log | sort | uniq -c
```

### Step 3 — Sort highest first, show top 5
```bash
cut -d' ' -f1 access.log | sort | uniq -c | sort -nr | head -n 5
```

---

# 6) Example: Find failing HTTP status codes (500/502) with counts
### Goal: “How many 500/502 responses happened?”

### Step 1 — Show only lines with 500 or 502
```bash
grep ' 500 ' access.log
grep ' 502 ' access.log
```

### Step 2 — Combine 500 and 502 using extended regex
```bash
grep -E ' (500|502) ' access.log
```

### Step 3 — Extract only the status code and count
```bash
grep -E ' (500|502) ' access.log | awk '{print $9}' | sort | uniq -c | sort -nr
```

---

# 7) Example: Monitor live errors while an app runs
### Goal: “Watch only errors live”

```bash
tail -f app.log | grep "ERROR"
```

> If your `grep` doesn’t show lines due to buffering, use:
```bash
tail -f app.log | grep --line-buffered "ERROR"
```

---

# 8) Example: Extract and uppercase city names from a CSV
### Goal: “Get all cities in uppercase”

### Step 1 — Extract city column (3rd field)
```bash
cut -d',' -f3 sales.csv
```

### Step 2 — Remove header row
```bash
cut -d',' -f3 sales.csv | tail -n +2
```

### Step 3 — Convert to uppercase
```bash
cut -d',' -f3 sales.csv | tail -n +2 | tr 'a-z' 'A-Z'
```

---

# 9) Example: Total amount of PAID orders from CSV
### Goal: “Sum the amount where status is PAID”

### Step 1 — View PAID rows (excluding header)
```bash
tail -n +2 sales.csv | grep ",PAID$"
```

### Step 2 — Sum amount (4th column)
```bash
tail -n +2 sales.csv | grep ",PAID$" | awk -F',' '{sum += $4} END {print sum}'
```

---

# 10) Example: Show only the URL paths from access log
### Goal: “Which endpoints are being called?”

### Step 1 — Print the request field (it includes "GET /path HTTP/1.1")
```bash
awk -F'"' '{print $2}' access.log
```

### Step 2 — Keep only the path (second token inside request)
```bash
awk -F'"' '{print $2}' access.log | awk '{print $2}'
```

### Step 3 — Count endpoints
```bash
awk -F'"' '{print $2}' access.log | awk '{print $2}' | sort | uniq -c | sort -nr
```

---

# 11) Example: Clean extra spaces in text (normalizing)
### Goal: “Replace multiple spaces with a single space”

```bash
cat app.log | tr -s ' '
```

> `tr -s` “squeezes” repeated characters.

---

# 12) Example: Find large files and sort by size
### Goal: “Top 10 largest files in current folder”

```bash
du -ah . | sort -hr | head -n 10
```

✅ `-h` = human size; `-r` reverse; `-n` numeric (for `sort -h` works well).

---

# 13) Example: Extract usernames from /etc/passwd
### Goal: “List system usernames”

```bash
cut -d: -f1 /etc/passwd | sort | head
```

---

# 14) Example: Combine pipes with xargs (batch operations)
### Goal: “Find .log files and show their line counts”

```bash
find . -name "*.log" | xargs wc -l
```

> If filenames may contain spaces, safer:
```bash
find . -name "*.log" -print0 | xargs -0 wc -l
```

---

# 15) Example: Build a quick “report file” (redirect output)
### Goal: “Save pipeline result into a report”

```bash
grep "ERROR" app.log | grep -o "code=[A-Z0-9]*" | sort | uniq -c | sort -nr > error_report.txt
cat error_report.txt
```

---

# Quick Cheat Sheet (Most used filters)

- `grep` → filter lines by pattern  
- `sort` → sort lines  
- `uniq -c` → remove duplicates + count  
- `head` / `tail` → take top/bottom lines  
- `cut` → split columns by delimiter  
- `tr` → translate/replace characters  
- `awk` → powerful field processing + calculations  
- `sed` → text replacement/editing  

---

## Next Practice Challenge (do it yourself)
Using `access.log`, create a pipeline that prints:

1) only the status codes  
2) count each code  
3) show top status codes first  

**Hint:**
```bash
awk '{print $9}' access.log | sort | uniq -c | sort -nr
```

---

If you want, tell me which log format you use (Nginx/Apache/app log), and I’ll tailor 20+ pipelines exactly for that.
